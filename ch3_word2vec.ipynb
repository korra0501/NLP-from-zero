{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitbasecondac1ab1b3ac90d4e2981ba357c16f579f5",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "이 장에서 다룰 것도 마찬가지로 단어의 분산표현이다. 여기서는 '추론에 기반한 방법'에 대해 알아볼 것이다.\n",
    "먼저, word2vec을 실제로 코드로 짜보자!\n",
    "\n",
    "## 추론 기반의 방법과 신경망\n",
    "단어를 벡터로 표현한 방법 중, 성공한 것은 '카운트 기반 방법'과 '추론 기반 방법'이다. 이 두가지 방법의 배경에는 분배가설이 있다.\n",
    "\n",
    "### 카운트 기반의 방법의 문제점\n",
    "카운트 기반의 문제점은, 역시 어휘가 많아질 때 늘어난다. 어휘량이 100만개라고 할 때, 이 방식으로는 100만 x 100만의 거대한 행렬을 만들게 된다. 이 때, 이렇게 커다란 행렬에 대해 특이값분해를 하는 것은 현실적으로 불가능하다.\n",
    "\n",
    "카운트 기반 방법은 코퍼스 전체의 통계 데이터(cocurrence matrix나 ppmi 등)을 이용해, 1회의 처리(SVD 등)으로 단어의 분산표현을 얻는다. 반면, 추론 기반 방법은 미니배치를 이용한 학습을 진행한다. 따라서 연산의 부하가 덜 걸리게 된다.\n",
    "\n",
    "### 추론 기반의 방법 개요\n",
    "추론 기반은 말 그대로 문맥이 주어졌을 때, 중간에 구멍을 뚫어놓고 어떤 단어가 출현할지 추측하는 것이다. 이런 추측을 거듭하여, 단어의 출현 패턴을 학습한다.\n",
    "\n",
    "우리는 앞으로 신경망으로 단어를 처리할 것이다. 그러나, 'you'나 'will'같은 단어를 컴퓨터가 그대로 처리하지는 못한다. 신경망에 통과시키기 위해서는, 벡터로 변환할 필요가 있다. 이 방법 중 하나는 단어를 one-hot vector로 변환하는 것이다.\n",
    "\n",
    "따라서, 모든 단어를 one-hot vector로 변환하면 이 벡터의 집합은 신경망을 구성하는 다양한 '레이어'에 의해 처리할 수 있다.\n",
    "그렇다면 예를 들어보자. \n",
    "\n",
    "아래 예에서 c와 W의 내적은, 단순히 W의 행벡터를 \"끄집어 내는\" 것에 지나지 않는다. 비효율적이다. 그래서 ch4에서는 이를 개량한 코드를 작성할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.32652697 -0.0091539   0.30483792]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# bias는 생략\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 입력층. 단어ID에 해당하는 원소는 1이고, 나머지는 0인 ONE-HOT VECTOR.\n",
    "W = np.random.randn(7,3) # weight\n",
    "h = np.dot(c, W) # 중간 노드\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-1.36072619 -1.54564841 -0.06030721]]\n"
    }
   ],
   "source": [
    "# Matmul layer를 사용해서 다시 쓸 수 있다.\n",
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dout(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx\n",
    "\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) # 입력층. 단어ID에 해당하는 원소는 1이고, 나머지는 0인 ONE-HOT VECTOR.\n",
    "W = np.random.randn(7,3) # weight\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망을 만들어 보자. word2vec에서 쓰이는 CBOW(Continuous Bag-of-words)라고 쓰이는 모델을 사용할 것이다.\n",
    "\n",
    "사실 word2vec이라는 용어는 모델이 아니라, 프로그램의 이름이다. 정확히는 CBOW 모델과 skip-gram 모델이라는 두 가지 모델이 word2vec에 사용되는 신경망이다.\n",
    "\n",
    "CBOW 모델은, 문맥에서 타겟(가운데 단어)을 추측하는 것을 목적으로 한 신경망이다. CBOW 모델이 입력받는 것은 문맥(컨텍스트)이다. 이 컨텍스트는 `['i', 'love', 'you']`와 같은 단어의 리스트로 표현된다. 이를 one-hot 표현으로 바꿔 CBOW 모델이 처리할 수 있게 변환할 것이다.\n",
    "\n",
    "CBOW의 입력층은 문맥의 단어 개수에 따라 결정된다. 만약 문맥으로 N개의 단어를 다룬다면 입력층은 N개가 된다. 입력층에서 중간층의 변환은, 같은 Affine layer(weight: Win)에 의해 이루어진다. 그리고 중간층에서 출력층의 변환은 다른 Affine layer(weight: Wout)에 의해 이루어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}